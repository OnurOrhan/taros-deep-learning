{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluation(leave one out) : ctc_loss_images- Revathi.ipynb","provenance":[{"file_id":"1SFdqchW7Lqp7nBA_lsP6yuB7MVQkVtGY","timestamp":1605820771540}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VJV6H7nnnNA8"},"source":["import os\n","import glob\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","from pathlib import Path\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBsHU3OFnSWD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605914113236,"user_tz":480,"elapsed":30051,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"d75f4aac-b69e-42ed-ab8f-6360565a8806"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd \"/gdrive/Shared drives/deep learning\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","/gdrive/Shared drives/deep learning\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zW-ITrnH-Lwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605914193003,"user_tz":480,"elapsed":1016,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"00bb4c9d-3e4c-4177-fdcd-ba2705baedbe"},"source":["omitting_medium_test = \"drums_2\"\n","omitting_medium_val = \"drums_2\"\n","\n","# Path to the data directory\n","data_dir = \"data/images_larger\"\n","label_path = \"data/labels.json\"\n","epochs = 50\n","\n","checkpoint_path = \"checkpoints/ctc_large_images\"\n","model_name = \"{}_epochs_{}\".format(epochs, omitting_medium_test)\n","model_save_path = os.path.join(checkpoint_path, model_name)\n","model_load_path = os.path.join(checkpoint_path, model_name)\n","history_path = \"history/ctc_large_images\"\n","history_name = \"{}_history\".format(omitting_medium_test)\n","history_save_path = os.path.join(history_path, history_name)\n","print(history_save_path)\n","#model.save_weights(model_save_path)\n","#model.load_weights(model_load_path)\n","\n","MAX_TEXT_SIZE=50\n","labels_train = []\n","labels_val = []\n","labels_test = []\n","# Get list of all the images\n","# images = glob.glob(os.path.join(data_dir, \"*.ogg.png\"))\n","images_train = [f for f in glob.glob(os.path.join(data_dir, \"*.ogg.png\")) if omitting_medium_test not in f and omitting_medium_val not in f]\n","text_labels_train = [img.split(os.path.sep)[-1].split(\".ogg.png\")[0] for img in images_train]\n","\n","with open(label_path) as f:\n","  data_dict = json.load(f)\n","  for l in text_labels_train:\n","    labels_train.append(data_dict[l].ljust(MAX_TEXT_SIZE).lower())\n","\n","images_val = [f for f in glob.glob(os.path.join(data_dir, \"*.ogg.png\")) if omitting_medium_val in f]\n","text_labels_val = [img.split(os.path.sep)[-1].split(\".ogg.png\")[0] for img in images_val]\n","\n","with open(label_path) as f:\n","  data_dict = json.load(f)\n","  for l in text_labels_val:\n","    labels_val.append(data_dict[l].ljust(MAX_TEXT_SIZE).lower())\n","\n","images_test = [f for f in glob.glob(os.path.join(data_dir, \"*.ogg.png\")) if omitting_medium_test in f]\n","text_labels_test = [img.split(os.path.sep)[-1].split(\".ogg.png\")[0] for img in images_test]\n","\n","with open(label_path) as f:\n","  data_dict = json.load(f)\n","  for l in text_labels_test:\n","    labels_test.append(data_dict[l].ljust(MAX_TEXT_SIZE).lower())\n","\n","characters = list('abcdefghijklmnopqrstuvwxyz0123456789,.?;:-_()=+@$!&/\\'\\\" ')\n","\n","print(\"Number of images found: \", len(images_train))\n","print(\"Number of labels found: \", len(labels_train))\n","print(\"Number of images found: \", len(images_test))\n","print(\"Number of labels found: \", len(labels_test))\n","print(\"Number of images found: \", len(images_val))\n","print(\"Number of labels found: \", len(labels_val))\n","print(\"Number of unique characters: \", len(characters))\n","print(\"Characters present: \", characters)\n","\n","batch_size = 32\n","\n","# Desired image dimensions\n","img_width = 650\n","img_height = 550\n","# Factor by which the image is going to be downsampled\n","# by the convolutional blocks. We will be using two\n","# convolution blocks and each block will have\n","# a pooling layer which downsample the features by a factor of 2.\n","# Hence total downsampling factor would be 4.\n","downsample_factor = 4\n","\n","# Maximum length of any captcha in the dataset\n","max_length = max([len(label) for label in labels_train])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["history/ctc_large_images/drums_2_history\n","Number of images found:  11289\n","Number of labels found:  11289\n","Number of images found:  948\n","Number of labels found:  948\n","Number of images found:  948\n","Number of labels found:  948\n","Number of unique characters:  55\n","Characters present:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', '.', '?', ';', ':', '-', '_', '(', ')', '=', '+', '@', '$', '!', '&', '/', \"'\", '\"', ' ']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jleWiwJroJXM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605914210723,"user_tz":480,"elapsed":6456,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"5d173ef7-ac20-4d07-cec9-f4055a27bebf"},"source":["char_to_num = layers.experimental.preprocessing.StringLookup(\n","    vocabulary=list(characters), num_oov_indices=0, mask_token=None\n",")\n","\n","# Mapping integers back to original characters\n","num_to_char = layers.experimental.preprocessing.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",")\n","\n","\n","# def split_data(images, labels, train_size=0.9, shuffle=True):\n","#     # 1. Get the total size of the dataset\n","#     size = len(images)\n","\n","#     # 2. Make an indices array and shuffle it, if required\n","#     indices = np.arange(size)\n","#     if shuffle:\n","#         np.random.shuffle(indices)\n","\n","#     # 3. Get the size of training samples\n","#     train_samples = int(size * train_size)\n","\n","#     # 4. Split data into training and test sets\n","#     x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n","#     x_test, y_test = images[indices[train_samples:]], labels[indices[train_samples:]]\n","#     return x_train, x_test, y_train, y_test\n","\n","# Splitting data into training and validation sets\n","# x_train, x_val, y_train, y_val = split_data(np.array(images_train), np.array(labels_train))\n","\n","x_train, y_train = np.array(images_train), np.array(labels_train)\n","x_val, y_val = np.array(images_val), np.array(labels_val)\n","x_test, y_test = np.array(images_test), np.array(labels_test)\n","\n","print(x_train.shape, y_train.shape)\n","print(x_val.shape, y_val.shape)\n","print(x_test.shape, y_test.shape)\n","\n","def encode_single_sample(img_path, label):\n","    # 1. Read image\n","    img = tf.io.read_file(img_path)\n","    # 2. Decode and convert to grayscale\n","    img = tf.io.decode_png(img, channels=1)\n","    # 3. Convert to float32 in [0, 1] range\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    # 4. Resize to the desired size\n","    img = tf.image.resize(img, [img_height, img_width])\n","    # 5. Transpose the image because we want the time\n","    # dimension to correspond to the width of the image.\n","    img = tf.transpose(img, perm=[1, 0, 2])\n","    # 6. Map the characters in label to numbers\n","    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n","    # 7. Return a dict as our model is expecting two inputs\n","    return {\"image\": img, \"label\": label}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(11289,) (11289,)\n","(948,) (948,)\n","(948,) (948,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPK3laGsoWUb"},"source":["train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_dataset = (\n","    train_dataset.map(\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    )\n","    .batch(batch_size)\n","    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",")\n","\n","shuffle_buffer_size = len(train_dataset)\n","train_dataset = train_dataset.shuffle(shuffle_buffer_size)\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","val_dataset = (\n","    val_dataset.map(\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    )\n","    .batch(batch_size)\n","    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",")\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","test_dataset = (\n","    test_dataset.map(\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    )\n","    .batch(batch_size)\n","    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uh4ovh_Koa4G"},"source":["# for batch in train_dataset.take(1):\n","#   images = batch[\"image\"]\n","#   labels = batch[\"label\"]\n","#   print(labels)\n","#   break\n","# print(text_labels[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQHXjDM44dwC"},"source":["# n = 3\n","# # print(train_dataset.take(1))\n","# _, ax = plt.subplots(n, n, figsize=(n*6, n*2))\n","# for batch in train_dataset.take(1):\n","#     images = batch[\"image\"][:10]\n","#     labels = batch[\"label\"][:10]\n","#     for i in range(n**2):\n","#         img = (images[i] * 255).numpy().astype(\"uint8\")\n","#         label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n","#         ax[i // n, i % n].imshow(img[:, :, 0].T, cmap=\"gray\")\n","#         ax[i // n, i % n].set_title(label)\n","#         ax[i // n, i % n].axis(\"off\")\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_OHXgf4oc1i"},"source":["class CTCLayer(layers.Layer):\n","    def __init__(self, name=None):\n","        super().__init__(name=name)\n","        self.loss_fn = keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        # Compute the training-time loss value and add it\n","        # to the layer using `self.add_loss()`.\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","\n","        # At test time, just return the computed predictions\n","        return y_pred\n","\n","\n","def build_model():\n","    # Inputs to the model\n","    input_img = layers.Input(\n","        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n","    )\n","    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n","\n","    # First conv block\n","    x = layers.Conv2D(\n","        64,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv1\",\n","    )(input_img)\n","    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n","\n","    # Second conv block\n","    x = layers.Conv2D(\n","        32,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv2\",\n","    )(x)\n","    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n","\n","    # We have used two max pool with pool size and strides 2.\n","    # Hence, downsampled feature maps are 4x smaller. The number of\n","    # filters in the last layer is 64. Reshape accordingly before\n","    # passing the output to the RNN part of the model\n","    new_shape = ((img_width // 4), (img_height // 4) * 32)\n","    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n","    x = layers.Dense(32, activation=\"relu\", name=\"dense1\")(x)\n","    x = layers.Dropout(0.2)(x)\n","\n","    # RNNs\n","    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n","    #x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n","\n","    # Output layer\n","    x = layers.Dense(len(characters) + 1, activation=\"softmax\", name=\"dense2\")(x)\n","\n","    # Add CTC layer for calculating CTC loss at each step\n","    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n","\n","    # Define the model\n","    model = keras.models.Model(\n","        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n","    )\n","    # Optimizer\n","    opt = keras.optimizers.Adam()\n","    # Compile the model and return\n","    model.compile(optimizer=opt,metrics = [tf.keras.metrics.Accuracy()])\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btReUhq_oipw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605914248525,"user_tz":480,"elapsed":2101,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"d1ce773a-e347-4685-d508-bd56f0eb9d6e"},"source":["model = build_model()\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ocr_model_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","image (InputLayer)              [(None, 650, 550, 1) 0                                            \n","__________________________________________________________________________________________________\n","Conv1 (Conv2D)                  (None, 650, 550, 64) 640         image[0][0]                      \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 325, 275, 64) 0           Conv1[0][0]                      \n","__________________________________________________________________________________________________\n","Conv2 (Conv2D)                  (None, 325, 275, 32) 18464       pool1[0][0]                      \n","__________________________________________________________________________________________________\n","pool2 (MaxPooling2D)            (None, 162, 137, 32) 0           Conv2[0][0]                      \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 162, 4384)    0           pool2[0][0]                      \n","__________________________________________________________________________________________________\n","dense1 (Dense)                  (None, 162, 32)      140320      reshape[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 162, 32)      0           dense1[0][0]                     \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 162, 256)     164864      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","label (InputLayer)              [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","dense2 (Dense)                  (None, 162, 56)      14392       bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","ctc_loss (CTCLayer)             (None, 162, 56)      0           label[0][0]                      \n","                                                                 dense2[0][0]                     \n","==================================================================================================\n","Total params: 338,680\n","Trainable params: 338,680\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sw7vnp7sdM5"},"source":["# epochs = epochs\n","# early_stopping_patience = 5\n","# # Add early stopping\n","# early_stopping = keras.callbacks.EarlyStopping(\n","#     monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n","# )\n","\n","# # Train the model\n","# history = model.fit(\n","#     train_dataset,\n","#     validation_split=0.2,\n","#     epochs=epochs,\n","#     callbacks=[early_stopping])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NncOHMWCol__","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605924581789,"user_tz":480,"elapsed":4073891,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"b3a0d0b8-f95d-4d55-9915-1794dc575498"},"source":["epochs = epochs\n","early_stopping_patience = 5\n","# Add early stopping\n","early_stopping = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data = val_dataset,\n","    epochs=epochs)\n","    # callbacks=[early_stopping])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","353/353 [==============================] - 265s 751ms/step - loss: 164.1114 - accuracy: 0.0000e+00 - val_loss: 144.9337 - val_accuracy: 0.0000e+00\n","Epoch 2/50\n","353/353 [==============================] - 88s 249ms/step - loss: 110.1783 - accuracy: 0.0000e+00 - val_loss: 48.3331 - val_accuracy: 0.0000e+00\n","Epoch 3/50\n","353/353 [==============================] - 87s 248ms/step - loss: 56.2861 - accuracy: 0.0000e+00 - val_loss: 21.3291 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","353/353 [==============================] - 87s 248ms/step - loss: 37.2127 - accuracy: 0.0000e+00 - val_loss: 14.0890 - val_accuracy: 0.0000e+00\n","Epoch 5/50\n","353/353 [==============================] - 87s 246ms/step - loss: 27.9331 - accuracy: 0.0000e+00 - val_loss: 11.8752 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","353/353 [==============================] - 87s 247ms/step - loss: 22.5119 - accuracy: 0.0000e+00 - val_loss: 9.5910 - val_accuracy: 0.0000e+00\n","Epoch 7/50\n","353/353 [==============================] - 87s 246ms/step - loss: 19.6060 - accuracy: 0.0000e+00 - val_loss: 7.8453 - val_accuracy: 0.0000e+00\n","Epoch 8/50\n","353/353 [==============================] - 87s 246ms/step - loss: 16.9485 - accuracy: 0.0000e+00 - val_loss: 7.5128 - val_accuracy: 0.0000e+00\n","Epoch 9/50\n","353/353 [==============================] - 87s 246ms/step - loss: 14.7195 - accuracy: 0.0000e+00 - val_loss: 5.7762 - val_accuracy: 0.0000e+00\n","Epoch 10/50\n","353/353 [==============================] - 87s 246ms/step - loss: 13.4986 - accuracy: 0.0000e+00 - val_loss: 6.3663 - val_accuracy: 0.0000e+00\n","Epoch 11/50\n","353/353 [==============================] - 87s 246ms/step - loss: 11.9785 - accuracy: 0.0000e+00 - val_loss: 5.3123 - val_accuracy: 0.0000e+00\n","Epoch 12/50\n","353/353 [==============================] - 87s 246ms/step - loss: 11.3626 - accuracy: 0.0000e+00 - val_loss: 5.0457 - val_accuracy: 0.0000e+00\n","Epoch 13/50\n","353/353 [==============================] - 87s 246ms/step - loss: 11.4749 - accuracy: 0.0000e+00 - val_loss: 4.4086 - val_accuracy: 0.0000e+00\n","Epoch 14/50\n","353/353 [==============================] - 87s 245ms/step - loss: 9.1078 - accuracy: 0.0000e+00 - val_loss: 5.1084 - val_accuracy: 0.0000e+00\n","Epoch 15/50\n","353/353 [==============================] - 86s 245ms/step - loss: 8.3654 - accuracy: 0.0000e+00 - val_loss: 5.4336 - val_accuracy: 0.0000e+00\n","Epoch 16/50\n","353/353 [==============================] - 86s 245ms/step - loss: 8.2513 - accuracy: 0.0000e+00 - val_loss: 4.2566 - val_accuracy: 0.0000e+00\n","Epoch 17/50\n","353/353 [==============================] - 86s 245ms/step - loss: 8.3274 - accuracy: 0.0000e+00 - val_loss: 4.1424 - val_accuracy: 0.0000e+00\n","Epoch 18/50\n","353/353 [==============================] - 86s 245ms/step - loss: 7.0960 - accuracy: 0.0000e+00 - val_loss: 3.4427 - val_accuracy: 0.0000e+00\n","Epoch 19/50\n","353/353 [==============================] - 86s 245ms/step - loss: 11.1686 - accuracy: 0.0000e+00 - val_loss: 4.3158 - val_accuracy: 0.0000e+00\n","Epoch 20/50\n","353/353 [==============================] - 86s 244ms/step - loss: 6.6204 - accuracy: 0.0000e+00 - val_loss: 5.2366 - val_accuracy: 0.0000e+00\n","Epoch 21/50\n","353/353 [==============================] - 86s 244ms/step - loss: 7.5762 - accuracy: 0.0000e+00 - val_loss: 3.9082 - val_accuracy: 0.0000e+00\n","Epoch 22/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.7698 - accuracy: 0.0000e+00 - val_loss: 4.1637 - val_accuracy: 0.0000e+00\n","Epoch 23/50\n","353/353 [==============================] - 86s 245ms/step - loss: 6.8867 - accuracy: 0.0000e+00 - val_loss: 3.3555 - val_accuracy: 0.0000e+00\n","Epoch 24/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.4425 - accuracy: 0.0000e+00 - val_loss: 4.3270 - val_accuracy: 0.0000e+00\n","Epoch 25/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.0023 - accuracy: 0.0000e+00 - val_loss: 2.9795 - val_accuracy: 0.0000e+00\n","Epoch 26/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.0406 - accuracy: 0.0000e+00 - val_loss: 2.8873 - val_accuracy: 0.0000e+00\n","Epoch 27/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.0751 - accuracy: 0.0000e+00 - val_loss: 3.6165 - val_accuracy: 0.0000e+00\n","Epoch 28/50\n","353/353 [==============================] - 86s 244ms/step - loss: 4.5112 - accuracy: 0.0000e+00 - val_loss: 5.2624 - val_accuracy: 0.0000e+00\n","Epoch 29/50\n","353/353 [==============================] - 86s 244ms/step - loss: 5.5245 - accuracy: 0.0000e+00 - val_loss: 59.6466 - val_accuracy: 0.0000e+00\n","Epoch 30/50\n","353/353 [==============================] - 86s 244ms/step - loss: 6.7602 - accuracy: 0.0000e+00 - val_loss: 2.8826 - val_accuracy: 0.0000e+00\n","Epoch 31/50\n","353/353 [==============================] - 86s 244ms/step - loss: 4.2114 - accuracy: 0.0000e+00 - val_loss: 2.7144 - val_accuracy: 0.0000e+00\n","Epoch 32/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.9197 - accuracy: 0.0000e+00 - val_loss: 4.8267 - val_accuracy: 0.0000e+00\n","Epoch 33/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.8992 - accuracy: 0.0000e+00 - val_loss: 2.7871 - val_accuracy: 0.0000e+00\n","Epoch 34/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.8392 - accuracy: 0.0000e+00 - val_loss: 2.8288 - val_accuracy: 0.0000e+00\n","Epoch 35/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.7773 - accuracy: 0.0000e+00 - val_loss: 2.8739 - val_accuracy: 0.0000e+00\n","Epoch 36/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.4922 - accuracy: 0.0000e+00 - val_loss: 2.5721 - val_accuracy: 0.0000e+00\n","Epoch 37/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.7093 - accuracy: 0.0000e+00 - val_loss: 2.6626 - val_accuracy: 0.0000e+00\n","Epoch 38/50\n","353/353 [==============================] - 86s 243ms/step - loss: 3.8664 - accuracy: 0.0000e+00 - val_loss: 3.0999 - val_accuracy: 0.0000e+00\n","Epoch 39/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.3391 - accuracy: 0.0000e+00 - val_loss: 4.4371 - val_accuracy: 0.0000e+00\n","Epoch 40/50\n","353/353 [==============================] - 86s 243ms/step - loss: 3.3857 - accuracy: 0.0000e+00 - val_loss: 3.2791 - val_accuracy: 0.0000e+00\n","Epoch 41/50\n","353/353 [==============================] - 86s 244ms/step - loss: 3.4285 - accuracy: 0.0000e+00 - val_loss: 2.6309 - val_accuracy: 0.0000e+00\n","Epoch 42/50\n","353/353 [==============================] - 86s 243ms/step - loss: 2.8661 - accuracy: 0.0000e+00 - val_loss: 2.5806 - val_accuracy: 0.0000e+00\n","Epoch 43/50\n","353/353 [==============================] - 86s 243ms/step - loss: 3.3745 - accuracy: 0.0000e+00 - val_loss: 33.5962 - val_accuracy: 0.0000e+00\n","Epoch 44/50\n","353/353 [==============================] - 86s 243ms/step - loss: 3.6969 - accuracy: 0.0000e+00 - val_loss: 2.5148 - val_accuracy: 0.0000e+00\n","Epoch 45/50\n","353/353 [==============================] - 86s 244ms/step - loss: 2.8932 - accuracy: 0.0000e+00 - val_loss: 2.9224 - val_accuracy: 0.0000e+00\n","Epoch 46/50\n","353/353 [==============================] - 86s 243ms/step - loss: 2.8969 - accuracy: 0.0000e+00 - val_loss: 2.1800 - val_accuracy: 0.0000e+00\n","Epoch 47/50\n","353/353 [==============================] - 86s 243ms/step - loss: 2.8824 - accuracy: 0.0000e+00 - val_loss: 4.9535 - val_accuracy: 0.0000e+00\n","Epoch 48/50\n","353/353 [==============================] - 86s 243ms/step - loss: 5.5605 - accuracy: 0.0000e+00 - val_loss: 2.4525 - val_accuracy: 0.0000e+00\n","Epoch 49/50\n","353/353 [==============================] - 86s 243ms/step - loss: 2.4154 - accuracy: 0.0000e+00 - val_loss: 1.9517 - val_accuracy: 0.0000e+00\n","Epoch 50/50\n","353/353 [==============================] - 86s 243ms/step - loss: 2.3040 - accuracy: 0.0000e+00 - val_loss: 6.0850 - val_accuracy: 0.0000e+00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pOFOW9Gjme91"},"source":["with open(history_save_path, 'wb') as file:\n","  pickle.dump(history.history, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ugg7MyWomsg"},"source":["# with open(history_save_path, 'rb') as file:\n","#   h = pickle.load(file)\n","# print(h) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BjrtEEm3zG3","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1605926893611,"user_tz":480,"elapsed":811,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"6a072b78-9c5e-4186-f6d7-4b3e4cd64b95"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"VVK9CJG_EgQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605926905104,"user_tz":480,"elapsed":9270,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"fef68b2b-7690-42ff-fe7b-16b1ca6b4438"},"source":["model.evaluate(test_dataset) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["30/30 [==============================] - 7s 239ms/step - loss: 6.0850 - accuracy: 0.0000e+00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[6.0849995613098145, 0.0]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"i7CoJ2Zq3rxg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605926961000,"user_tz":480,"elapsed":10620,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"05688263845536493182"}},"outputId":"67515e58-38b1-4db8-c527-efd72d1e1117"},"source":["# Get the prediction model by extracting layers till the output layer\n","prediction_model = keras.models.Model(\n","    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",")\n","#prediction_model.summary()\n","\n","# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n","        :, :max_length\n","    ]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for res in results:\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n","        output_text.append(res)\n","    return output_text\n","\n","\n","def count_num_errors(pred_texts, orig_texts):\n","  err_w = 0\n","  err_c = 0\n","  total_words = 0\n","  total_chars = 0\n","  for i in range(len(pred_texts)):\n","    pred_text = pred_texts[i]\n","    orig_text = orig_texts[i]\n","\n","    pred_tokens = pred_text.split()\n","    orig_tokens = orig_text.split()\n","\n","    pred_w_len = len(pred_tokens)\n","    orig_w_len = len(orig_tokens)\n","    total_words += max(pred_w_len, orig_w_len)\n","    # err_w = 0\n","    for w in range(min(pred_w_len, orig_w_len)):\n","      if pred_tokens[w] != orig_tokens[w]:\n","        err_w += 1\n","    \n","    pred_c_len = len(pred_text)\n","    orig_c_len = len(orig_text)\n","    total_chars += max(pred_c_len, orig_c_len)\n","\n","    for c in range(min(pred_c_len, orig_c_len)):\n","      if pred_text[c] != orig_text[c]:\n","        err_c += 1\n","  return err_w, total_words, err_c, total_chars\n","\n","\n","# For random sampling from each batch\n","import random\n","samples_per_batch = 1\n","sample_text = \"\"\n","err_w, total_words, err_c, total_chars = 0, 0, 0, 0\n","\n","# Iterate over the test dataset batches\n","sample_ind = 1\n","for batch in test_dataset.as_numpy_iterator():\n","  batch_images = batch[\"image\"]\n","  batch_labels = batch[\"label\"]\n","  \n","  preds = prediction_model.predict(batch_images)\n","  pred_texts = decode_batch_predictions(preds)\n","\n","  orig_texts = []\n","  for label in batch_labels:\n","    label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","    orig_texts.append(label)\n","\n","  m1, m2, m3, m4 = count_num_errors(pred_texts, orig_texts)\n","  err_w += m1\n","  total_words += m2\n","  err_c += m3\n","  total_chars += m4\n","\n","  if random.random() < 0.4:\n","    batch_size = len(pred_texts)\n","    sample_indices = random.sample(range(batch_size), samples_per_batch)\n","    for i in sample_indices:\n","      sample_text += \"Sample #{}\\n\".format(sample_ind)\n","      sample_text += \"Ground truth:  \\t{}\\n\".format(orig_texts[i])\n","      sample_text += \"Reconstruction:\\t{}\\n\\n\".format(pred_texts[i])\n","      sample_ind += 1\n","\n","word_error = err_w / total_words if total_words != 0 else 0\n","char_error = err_c / total_chars if total_chars != 0 else 0\n","accuracy_text = \"Accurate words: \\t{}/{}\\n\".format(total_words - err_w, total_words)\n","accuracy_text += \"Word level accuracy: \\t{}\\n\\n\".format(1 - word_error)\n","accuracy_text += \"Accurate chars: \\t{}/{}\\n\".format(total_chars - err_c, total_chars)\n","accuracy_text += \"Char level accuracy: \\t{}\\n\".format(1 - char_error)\n","\n","print(accuracy_text)\n","print(sample_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accurate words: \t7217/8392\n","Word level accuracy: \t0.8599857006673022\n","\n","Accurate chars: \t37138/49264\n","Char level accuracy: \t0.7538567716791166\n","\n","Sample #1\n","Ground truth:  \tdiana bridget alice dean (born september 29, 1942)\n","Reconstruction:\tdiana bridget alice dean (born september 29, 1942)\n","\n","Sample #2\n","Ground truth:  \tthere are at least 70 described species in germaro\n","Reconstruction:\tthere are at least 7 described species in germaro[UNK]\n","\n","Sample #3\n","Ground truth:  \toriginated from afghanistan and migrated to india.\n","Reconstruction:\toriginated from afghanistan and migrated to india \n","\n","Sample #4\n","Ground truth:  \tshe was the secretary-organizer of the huddersfiel\n","Reconstruction:\tshe was the secretar-organizer of the huddersfiel[UNK]\n","\n","Sample #5\n","Ground truth:  \tstarytsky is currently remembered for his work wit\n","Reconstruction:\tstarytsky is currently remembered for his work wit\n","\n","Sample #6\n","Ground truth:  \tit is scheduled to hold five sessions in this peri\n","Reconstruction:\tit is scheduled to hold five sessions in this peri\n","\n","Sample #7\n","Ground truth:  \tthe newbear 77-68 was a kit of parts from which a \n","Reconstruction:\tthe newbear 77-68 was a kit of parts from which a \n","\n","Sample #8\n","Ground truth:  \tin my world of beautiful things has never been off\n","Reconstruction:\tin my worlid of beautifu things has never been off\n","\n","Sample #9\n","Ground truth:  \tmi marathi was an entertainment television channel\n","Reconstruction:\tmi marathi was an entertainment television channel\n","\n","Sample #10\n","Ground truth:  \tthis is a list of potentially habitable exoplanets\n","Reconstruction:\tthis is a list of potentially habitable exoplanets\n","\n","Sample #11\n","Ground truth:  \tmathias blad (born 1973) is a swedish actor and si\n","Reconstruction:\tmathias blad (born 1973) is a swedish actotr and s\n","\n","Sample #12\n","Ground truth:  \tbruce kingma (born october 4, 1961 in chicago, ill\n","Reconstruction:\tfruce kingma (born october 4, 1961 in chicago, il[UNK]\n","\n","Sample #13\n","Ground truth:  \tin november 2011 vizzini abruptly left the pdl in \n","Reconstruction:\tin novembder 2012 vizzini abrugtly left the gl in \n","\n","Sample #14\n","Ground truth:  \tmarcus aemilius lepidus (d. 216 bc) was the roman \n","Reconstruction:\tmarcus aemilius epidus (d. 216 bc) was the roman [UNK]\n","\n","Sample #15\n","Ground truth:  \tit was named song of the year at the 2014 cma awar\n","Reconstruction:\tit was named song of the year at the 2014 ca awar[UNK]\n","\n","Sample #16\n","Ground truth:  \ta smart battery can demand that the charging stop,\n","Reconstruction:\ta smart battery can demand that the charging stog,\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WXgr1v9QN4KG","executionInfo":{"status":"error","timestamp":1606234215511,"user_tz":480,"elapsed":485,"user":{"displayName":"Revathi Mukkamala","photoUrl":"","userId":"00409309097788316410"}},"outputId":"36df0271-0f0a-4c4f-acf3-819c11ac21ee","colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["model.save_weights(model_save_path)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-58b8ec0e96bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]}]}